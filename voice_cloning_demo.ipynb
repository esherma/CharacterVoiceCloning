{
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  },
  "colab": {
   "provenance": [],
   "gpuType": "T4"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "markdown",
   "id": "intro",
   "metadata": {},
   "source": [
    "# Voice Cloning with Qwen3-TTS\n",
    "\n",
    "Clone any voice from a short reference clip using [Qwen3-TTS](https://github.com/QwenLM/Qwen3-TTS) (0.6B model, faster than real-time on GPU).\n",
    "\n",
    "Provide a 10–30 second WAV file and a transcript of what's said in it, then type any text to generate new speech in that voice.\n",
    "\n",
    "> **⚠️ Important:** Only use reference audio you own or have explicit rights to clone. This notebook is for personal, non-commercial use.\n",
    "\n",
    "**Before running:** Go to **Runtime → Change runtime type → T4 GPU** to enable GPU acceleration."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "setup-header",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "install",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install Qwen3-TTS — see https://github.com/QwenLM/Qwen3-TTS for the latest instructions\n",
    "!pip install -q git+https://github.com/QwenLM/Qwen3-TTS.git soundfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "device-check",
   "metadata": {},
   "outputs": [],
   "source": "import torch\nimport soundfile as sf\nfrom IPython.display import Audio, display\n\nif not torch.cuda.is_available():\n    print(\"⚠️  No GPU detected. Go to Runtime → Change runtime type → T4 GPU.\")\n    print(\"    Generation will be extremely slow on CPU.\")\n    device = \"cpu\"\n    dtype = torch.float32\nelse:\n    device = \"cuda:0\"\n    # bfloat16 is supported on Ampere and newer (compute capability >= 8.0, e.g. A100, L4)\n    # T4 (capability 7.5) doesn't support bfloat16 — use float32 instead of float16,\n    # since float16's limited range can cause NaN logits in the acoustic code predictor.\n    dtype = torch.bfloat16 if torch.cuda.get_device_capability()[0] >= 8 else torch.float32\n    print(f\"✓ GPU: {torch.cuda.get_device_name(0)}\")\n    print(f\"  dtype: {dtype}\")"
  },
  {
   "cell_type": "markdown",
   "id": "step1-header",
   "metadata": {},
   "source": [
    "## Step 1: Upload your reference audio\n",
    "\n",
    "Upload a short WAV clip (10–30 seconds) of the voice you want to clone. Clean speech with minimal background noise works best."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "upload",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "\n",
    "print(\"Select a WAV file to upload...\")\n",
    "uploaded = files.upload()\n",
    "\n",
    "if not uploaded:\n",
    "    raise ValueError(\"No file uploaded.\")\n",
    "\n",
    "ref_audio_path = list(uploaded.keys())[0]\n",
    "print(f\"\\nReference clip: {ref_audio_path}\")\n",
    "display(Audio(ref_audio_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "step2-header",
   "metadata": {},
   "source": [
    "## Step 2: Set reference transcript and text to generate\n",
    "\n",
    "- **Reference transcript**: Type exactly what is said in your reference clip. Verbatim accuracy significantly improves cloning quality over using no transcript.\n",
    "- **Text to generate**: What you want the cloned voice to say."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "params",
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_text = \"Type the exact words spoken in your reference clip here.\" # @param {type:\"string\"}\n",
    "text_to_generate = \"Hello. I am functioning within normal parameters.\" # @param {type:\"string\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "step3-header",
   "metadata": {},
   "source": [
    "## Step 3: Load the model\n",
    "\n",
    "Downloads ~620 MB of weights on first run. Subsequent runs use the Colab cache."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "load-model",
   "metadata": {},
   "outputs": [],
   "source": [
    "from qwen_tts import Qwen3TTSModel\n",
    "\n",
    "model = Qwen3TTSModel.from_pretrained(\n",
    "    \"Qwen/Qwen3-TTS-12Hz-0.6B-Base\",\n",
    "    device_map=device,\n",
    "    dtype=dtype,\n",
    ")\n",
    "print(\"✓ Model loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "step4-header",
   "metadata": {},
   "source": [
    "## Step 4: Generate speech\n",
    "\n",
    "Run this cell to generate. To try different text, update `text_to_generate` in Step 2 and re-run this cell — no need to reload the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "generate",
   "metadata": {},
   "outputs": [],
   "source": [
    "wavs, sr = model.generate_voice_clone(\n",
    "    text=text_to_generate,\n",
    "    language=\"English\",\n",
    "    ref_audio=ref_audio_path,\n",
    "    ref_text=ref_text,\n",
    ")\n",
    "\n",
    "output_path = \"cloned_output.wav\"\n",
    "sf.write(output_path, wavs[0], sr)\n",
    "print(f\"Saved: {output_path}\")\n",
    "display(Audio(output_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tips",
   "metadata": {},
   "source": [
    "## Tips\n",
    "\n",
    "- **Transcript accuracy matters**: An exact verbatim transcript significantly outperforms x_vector-only mode (no transcript).\n",
    "- **Clip quality matters**: Clean speech with no background noise or music gives the best results. The [`data_extractor.py`](https://github.com/esherma/CharacterVoiceCloning/blob/main/data_extractor.py) script in this repo automates downloading and filtering clips from YouTube.\n",
    "- **Generating multiple lines**: Use `model.create_voice_clone_prompt()` once and pass the result as `voice_clone_prompt=` to avoid re-encoding the reference audio on every call. See the [Qwen3-TTS docs](https://github.com/QwenLM/Qwen3-TTS) for details.\n",
    "- **Download output**: Run `files.download('cloned_output.wav')` to save the result locally.\n",
    "\n",
    "---\n",
    "\n",
    "Built with [Qwen3-TTS](https://github.com/QwenLM/Qwen3-TTS) by Alibaba Qwen. See [CharacterVoiceCloning](https://github.com/esherma/CharacterVoiceCloning) for the full pipeline including YouTube extraction, clip filtering, and Claude Code hook integration."
   ]
  }
 ]
}